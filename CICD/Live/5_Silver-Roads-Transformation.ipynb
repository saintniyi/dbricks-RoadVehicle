{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c86240f4-285b-4f39-b396-58042117bd71",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Get environment name from widget and assign to variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c592fafc-4c90-4386-b1e6-e6ac1f69bcbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(name=\"env\", defaultValue='', label='Enter the environment in lower case')\n",
    "env = dbutils.widgets.get(\"env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b76a140-a5e7-41d4-97ed-954f80ec736c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "### Call common notebook to access shared variables and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c5531dd-a836-432b-84c8-2e6b1232d297",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run \"./3_Common\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e16554f8-9833-4254-9572-72bd09cc95b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Reading the data from bronze raw_roads Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f805c43-465b-4802-8ece-80a98edb5a7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_BronzeRoadsTable(environment):\n",
    "    print('Reading the Bronze Table raw_roads Data : ',end='')\n",
    "    df_bronzeRoads = (spark.readStream\n",
    "                    .table(f\"`{environment}_catalog`.`bronze`.raw_roads\")\n",
    "                    )\n",
    "    print(f'Reading {environment}_catalog.bronze.raw_roads Success!')\n",
    "    print(\"**********************************\")\n",
    "    return df_bronzeRoads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba19772e-9a93-44b0-b795-e9b078d9145c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Creating road_category_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f35afdec-4cf2-48f1-9e34-208f0628aff8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def road_Category(df):\n",
    "    \n",
    "    print('Creating Road Category Name Column: ', end='')\n",
    "\n",
    "    from pyspark.sql.functions import when, col\n",
    "\n",
    "    df_road_Cat = df.withColumn(\"Road_Category_Name\",\n",
    "                  when(col('Road_Category') == 'TA', 'Class A Trunk Road')\n",
    "                  .when(col('Road_Category') == 'TM', 'Class A Trunk Motor')\n",
    "                   .when(col('Road_Category') == 'PA','Class A Principal road')\n",
    "                    .when(col('Road_Category') == 'PM','Class A Principal Motorway')\n",
    "                    .when(col('Road_Category') == 'M','Class B road')\n",
    "                    .otherwise('NA')\n",
    "                  \n",
    "                  )\n",
    "    print('Success!! ')\n",
    "    print('***********************')\n",
    "    return df_road_Cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a3c5716-62b3-4a87-8fc9-105775140c3c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Creating road_type column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d423d77e-29aa-46f0-853c-008a4dff5516",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def road_Type(df):\n",
    "    \n",
    "    print('Creating Road Type Name Column: ', end='')\n",
    "\n",
    "    from pyspark.sql.functions import when, col\n",
    "\n",
    "    df_road_Type = df.withColumn(\"Road_Type\",\n",
    "                  when(col('Road_Category_Name').like('%Class A%'),'Major')\n",
    "                  .when(col('Road_Category_Name').like('%Class B%'),'Minor')\n",
    "                    .otherwise('NA')\n",
    "                  \n",
    "                  )\n",
    "    print('Success!! ')\n",
    "    print('***********************')\n",
    "    return df_road_Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a66cf121-a1cb-41b3-a04c-6009a2c747db",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c219ee7-fe83-4d40-bfab-b147fea55d1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def road_Type_Alt(df):\n",
    "    print('Creating Road Type Name Column: ', end='')\n",
    "\n",
    "    from pyspark.sql.functions import when, col\n",
    "\n",
    "    df_road_Type = df.withColumn(\"Road_Type\",\n",
    "                  when(col('Road_Category_Name').contains('Class A'), 'Major')\n",
    "                  .when(col('Road_Category_Name').contains('Class B'), 'Minor')\n",
    "                  .otherwise('NA')\n",
    "                  )\n",
    "    print('Success!! ')\n",
    "    print('***********************')\n",
    "    return df_road_Type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c6c15a9-2340-4a44-a1b7-3fee3b697b9b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Writing data to silver_roads in Silver schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebbe688b-3bd7-489c-8320-06d5b1ef380e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_Roads_SilverTable(StreamingDF, environment):\n",
    "\n",
    "    print('Writing the silver_roads Data : ',end='') \n",
    "\n",
    "    write_StreamSilver_Road = (StreamingDF.writeStream\n",
    "                .format('delta')\n",
    "                .option('checkpointLocation', checkpoint+ \"/SilverRoadsLoad/Checkpt/\")\n",
    "                .outputMode('append')\n",
    "                .queryName(\"SilverRoadsWriteStream\")\n",
    "                .trigger(availableNow=True)\n",
    "                .toTable(f\"`{environment}_catalog`.`silver`.`silver_roads`\"))\n",
    "    \n",
    "    write_StreamSilver_Road.awaitTermination()\n",
    "\n",
    "    print(f'Writing `{environment}_catalog`.`silver`.`silver_roads` Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "afe0adaf-71a2-4bdd-a6f1-e2b0df73d6dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Before adding new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e739b8b-3c27-427f-9a70-2e3692b651f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if the table exists\n",
    "tableExists = spark._jsparkSession.catalog().tableExists(f\"{env}_catalog.silver.silver_roads\")\n",
    "\n",
    "if tableExists:\n",
    "    # If the table exists, execute the query\n",
    "    query = f\"SELECT count(*) as `Num of Rows` FROM `{env}_catalog`.`silver`.`silver_roads`\"\n",
    "    df = spark.sql(query)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"Table does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5520a2cd-34e5-4fe1-83d4-186d2d4be13a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Calling all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21e5b090-7152-482f-9307-6338e6a999e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start by reading the data from the Bronze table\n",
    "df_roads = read_BronzeRoadsTable(env)\n",
    "\n",
    "# remove duplicates\n",
    "df_noDups = remove_Dups(df_roads)\n",
    "\n",
    "# Get dataframe columns name to a list\n",
    "AllColumns = df_noDups.schema.names\n",
    "\n",
    "# Handle null values in strings and numeric datatypes\n",
    "df_clean = handle_NULLs(df_noDups, AllColumns)\n",
    "\n",
    "## Creating Road_Category_name \n",
    "df_roadCat = road_Category(df_clean)\n",
    "\n",
    "## Creating Road_Type column\n",
    "df_type = road_Type(df_roadCat)\n",
    "\n",
    "## Writing data to silver_roads table\n",
    "write_Roads_SilverTable(df_type,env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce14a25d-5538-4b57-90e7-afac725cef8a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### After adding new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d0b54e0-c1d9-4bd1-a998-902225c6ba16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT count(*) as `Num of Rows` FROM `dev_catalog`.`silver`.`silver_roads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a836959-f4c3-4e36-9b8e-2dc004b16e90",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Display small sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "787f33e9-6218-4610-a28c-dabcc2490e88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "SELECT * FROM `dev_catalog`.`silver`.`silver_roads` Limit 5"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3191140395212484,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "5_Silver-Roads-Transformation",
   "widgets": {
    "env": {
     "currentValue": "dev",
     "nuid": "a2272d04-2d4d-4bf1-a473-417ce16c5c53",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": "Enter the environment in lower case",
      "name": "env",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
